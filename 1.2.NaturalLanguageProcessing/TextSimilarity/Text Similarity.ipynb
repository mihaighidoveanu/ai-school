{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "# Some IPython magic\n",
    "# Put these at the top of every notebook, here nbagg is used for interactive plots\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Enable multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text similarity\n",
    "We will compute text similarity by measuring distances between word frequencies. For this, we will have to remove punctuation from the text. And for better results, we will also remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "from nltk import corpus\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "default_lemmatizer = WordNetLemmatizer()\n",
    "default_stemmer = PorterStemmer()\n",
    "\n",
    "def remove_chars(s, removals):\n",
    "    return s.translate(str.maketrans('', '', removals))\n",
    "\n",
    "def tokenize(text, lmtzr = default_lemmatizer, stmr = default_stemmer):\n",
    "    # remove punctuation\n",
    "    text = remove_chars(text, string.punctuation)\n",
    "    # remove numbers\n",
    "    words = [word.lower() for word in text.split() if word.isalpha()]\n",
    "#     words = [stmr.stem(word.lower()) for word in text.split() if word.isalpha()]\n",
    "#     words = [lmtzr.lemmatize(word.lower()) for word in text.split() if word.isalpha()]\n",
    "    # remove stopwords, but remove punctuation from the stopwords first because we removed all punctuation from the original text too\n",
    "    stopwords = set([remove_chars(sw, string.punctuation) for sw in corpus.stopwords.words('English')])\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    return words\n",
    "\n",
    "# count word frequencies\n",
    "def count_words(words, vocabulary):\n",
    "    # compute frequencies and vocabulary for list of words\n",
    "    fdist = nltk.FreqDist(words)\n",
    "    # add words that are in the vocabulary but not in the current list of words\n",
    "    words_not_present = [word for word in vocabulary if word not in fdist.keys()]\n",
    "    for word in words_not_present:\n",
    "        fdist[word] = 0\n",
    "    \n",
    "    v = np.array([fdist[word] for word in vocabulary])\n",
    "\n",
    "    return v\n",
    "\n",
    "def normalize(v):\n",
    "    return (v - v.min() ) / (v.max() - v.min())\n",
    "\n",
    "from math import acos, sqrt\n",
    "#compute distance according to formula\n",
    "# !!! arccos((V1*V2)/sqrt(V1*V1)*(V2*V2))\n",
    "def compute_distance(v1, v2):\n",
    "    distance = acos( (np.dot(v1,v2) / sqrt( (np.dot(v1,v1) * np.dot(v2,v2)))))\n",
    "    return distance\n",
    "\n",
    "def compute_similarity(text1, text2):\n",
    "    w1, w2 = tokenize(text1), tokenize(text2)\n",
    "    # create a sorted common vocabulary for the two lists of words\n",
    "    common_vocab = sorted(set(w1) | set(w2))\n",
    "    \n",
    "    # create count vectors of the same lenght for the two lists of words\n",
    "    v1 = count_words(w1, common_vocab)\n",
    "    v2 = count_words(w2, common_vocab)\n",
    "    \n",
    "    distance = compute_distance(v1, v2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "# wordnet.synsets('near')\n",
    "s = wordnet.synset('near.s.03')\n",
    "s.hypernyms()\n",
    "s.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0==========================\n",
      "A group of kids is playing in a yard and an old man is standing in the background \n",
      " A group of boys in a yard is playing and a man is standing in the background\n",
      "['background', 'boys', 'group', 'kids', 'man', 'old', 'playing', 'standing', 'yard']\n",
      "[1 0 1 1 1 1 1 1 1] \n",
      " [1 1 1 0 1 0 1 1 1]\n",
      "0.6405223126794245\n",
      "\n",
      "\n",
      "\n",
      "1==========================\n",
      "A group of children is playing in the house and there is no man standing in the background \n",
      " A group of kids is playing in a yard and an old man is standing in the background\n",
      "['background', 'children', 'group', 'house', 'kids', 'man', 'old', 'playing', 'standing', 'yard']\n",
      "[1 1 1 1 0 1 0 1 1 0] \n",
      " [1 0 1 0 1 1 1 1 1 1]\n",
      "0.8390726214483827\n",
      "\n",
      "\n",
      "\n",
      "2==========================\n",
      "The young boys are playing outdoors and the man is smiling nearby \n",
      " The kids are playing outdoors near a man with a smile\n",
      "['boys', 'kids', 'man', 'near', 'nearby', 'outdoors', 'playing', 'smile', 'smiling', 'young']\n",
      "[1 0 1 0 1 1 1 0 1 1] \n",
      " [0 1 1 1 0 1 1 1 0 0]\n",
      "1.0895209528525531\n",
      "\n",
      "\n",
      "\n",
      "3==========================\n",
      "The young boys are playing outdoors and the man is smiling nearby \n",
      " There is no boy playing outdoors and there is no man smiling\n",
      "['boy', 'boys', 'man', 'nearby', 'outdoors', 'playing', 'smiling', 'young']\n",
      "[0 1 1 1 1 1 1 1] \n",
      " [1 0 1 0 1 1 1 0]\n",
      "0.8283079586503962\n",
      "\n",
      "\n",
      "\n",
      "4==========================\n",
      "The kids are playing outdoors near a man with a smile \n",
      " A group of kids is playing in a yard and an old man is standing in the background\n",
      "['background', 'group', 'kids', 'man', 'near', 'old', 'outdoors', 'playing', 'smile', 'standing', 'yard']\n",
      "[0 0 1 1 1 0 1 1 1 0 0] \n",
      " [1 1 1 1 0 1 0 1 0 1 1]\n",
      "1.1229639298659642\n",
      "\n",
      "\n",
      "\n",
      "5==========================\n",
      "There is no boy playing outdoors and there is no man smiling \n",
      " A group of kids is playing in a yard and an old man is standing in the background\n",
      "['background', 'boy', 'group', 'kids', 'man', 'old', 'outdoors', 'playing', 'smiling', 'standing', 'yard']\n",
      "[0 1 0 0 1 0 1 1 1 0 0] \n",
      " [1 0 1 1 1 1 0 1 0 1 1]\n",
      "1.2490457723982544\n",
      "\n",
      "\n",
      "\n",
      "6==========================\n",
      "A group of boys in a yard is playing and a man is standing in the background \n",
      " The young boys are playing outdoors and the man is smiling nearby\n",
      "['background', 'boys', 'group', 'man', 'nearby', 'outdoors', 'playing', 'smiling', 'standing', 'yard', 'young']\n",
      "[1 1 1 1 0 0 1 0 1 1 0] \n",
      " [0 1 0 1 1 1 1 1 0 0 1]\n",
      "1.1278852827212578\n",
      "\n",
      "\n",
      "\n",
      "7==========================\n",
      "A group of children is playing in the house and there is no man standing in the background \n",
      " The young boys are playing outdoors and the man is smiling nearby\n",
      "['background', 'boys', 'children', 'group', 'house', 'man', 'nearby', 'outdoors', 'playing', 'smiling', 'standing', 'young']\n",
      "[1 0 1 1 1 1 0 0 1 0 1 0] \n",
      " [0 1 0 0 0 1 1 1 1 1 0 1]\n",
      "1.2810446253588492\n",
      "\n",
      "\n",
      "\n",
      "8==========================\n",
      "The young boys are playing outdoors and the man is smiling nearby \n",
      " A group of kids is playing in a yard and an old man is standing in the background\n",
      "['background', 'boys', 'group', 'kids', 'man', 'nearby', 'old', 'outdoors', 'playing', 'smiling', 'standing', 'yard', 'young']\n",
      "[0 1 0 0 1 1 0 1 1 1 0 0 1] \n",
      " [1 0 1 1 1 0 1 0 1 0 1 1 0]\n",
      "1.3002465638163236\n",
      "\n",
      "\n",
      "\n",
      "9==========================\n",
      "A brown dog is attacking another animal in front of the tall man in pants \n",
      " A brown dog is attacking another animal in front of the man in pants\n",
      "['animal', 'another', 'attacking', 'brown', 'dog', 'front', 'man', 'pants', 'tall']\n",
      "[1 1 1 1 1 1 1 1 1] \n",
      " [1 1 1 1 1 1 1 1 0]\n",
      "0.33983690945412165\n",
      "\n",
      "\n",
      "\n",
      "0.981844692925\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sick/SICK.txt', delimiter='\\t')\n",
    "ds = []\n",
    "for i in range(10):\n",
    "    text1 = df['sentence_A'][i]\n",
    "    text2 = df['sentence_B'][i]\n",
    "    w1, w2 = tokenize(text1), tokenize(text2)\n",
    "    # create a sorted common vocabulary for the two lists of words\n",
    "    common_vocab = sorted(set(w1) | set(w2))\n",
    "    \n",
    "    # create count vectors of the same lenght for the two lists of words\n",
    "    v1 = count_words(w1, common_vocab)\n",
    "    v2 = count_words(w2, common_vocab)\n",
    "    \n",
    "    distance = compute_distance(v1, v2)\n",
    "    ds.append(distance)\n",
    "    \n",
    "    print(str(i) + '==========================')\n",
    "    print(text1, '\\n', text2)\n",
    "    print(common_vocab)\n",
    "    print(v1, '\\n', v2)\n",
    "    print(distance)\n",
    "    print('\\n\\n')\n",
    "\n",
    "print(np.mean(ds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
